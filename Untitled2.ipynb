{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMc1sg+P1bqh5Q+OP6Ob5q2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dongnguyennhathuy260206-lab/Huy_Dong/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ƒë·ªì ƒÉn\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#x·ª≠ l√Ω th∆∞ m·ª•c, file c·ªßa data\n",
        "def load_data(data_dir, img_size=(60, 60), test_size=0.2):\n",
        "    X, y = [], []\n",
        "    class_names = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
        "    class_map = {cls_name: idx for idx, cls_name in enumerate(class_names)}\n",
        "\n",
        "    for cls in class_names:\n",
        "        cls_path = os.path.join(data_dir, cls)\n",
        "        for file in os.listdir(cls_path):\n",
        "            if file.lower().endswith((\".jpg\", \".png\", \".jpeg\", \".bmp\", \".HEIC\")):\n",
        "                img_path = os.path.join(cls_path, file)\n",
        "                try:\n",
        "                    img = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error decoding image {img_path}: {e}\")\n",
        "                    continue\n",
        "\n",
        "                    # Ti·ªÅn x·ª≠ l√Ω ·∫£nh\n",
        "                img = cv2.resize(img, img_size)\n",
        "                img = cv2.equalizeHist(img)  # C√¢n b·∫±ng histogram ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô t∆∞∆°ng ph·∫£n\n",
        "                img = cv2.GaussianBlur(img, (3, 3), 0)  # L√†m m·ªù ƒë·ªÉ gi·∫£m nhi·ªÖu\n",
        "                img = img.astype(\"float32\") / 255.0\n",
        "                X.append(img)\n",
        "                y.append(class_map[cls])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    X = X.reshape((X.shape[0], img_size[0] * img_size[1]))\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
        "    return (X_train, y_train), (X_test, y_test), class_names\n",
        "\n",
        "\n",
        "def create_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    # M·∫°ng neural s√¢u h∆°n v·ªõi c√°c k·ªπ thu·∫≠t ch·ªëng overfitting\n",
        "    model.add(Dense(1024, activation='relu', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # S·ª≠ d·ª•ng optimizer t·ªët h∆°n\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def augment_data(X_train, y_train):\n",
        "    # T·∫°o d·ªØ li·ªáu augmentation\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=20,  # Xoay ·∫£nh ng·∫´u nhi√™n ¬±20 ƒë·ªô\n",
        "        width_shift_range=0.2,  # D·ªãch chuy·ªÉn ngang ng·∫´u nhi√™n 20%\n",
        "        height_shift_range=0.2,  # D·ªãch chuy·ªÉn d·ªçc ng·∫´u nhi√™n 20%\n",
        "        shear_range=0.2,  # Bi·∫øn d·∫°ng c·∫Øt ng·∫´u nhi√™n 20%\n",
        "        zoom_range=0.2,  # Zoom ng·∫´u nhi√™n ¬±20%\n",
        "        horizontal_flip=True,  # L·∫≠t ngang ng·∫´u nhi√™n\n",
        "        fill_mode='nearest'  # ƒêi·ªÅn pixel g·∫ßn nh·∫•t khi bi·∫øn ƒë·ªïi\n",
        "    )\n",
        "\n",
        "    # Reshape d·ªØ li·ªáu ƒë·ªÉ ph√π h·ª£p v·ªõi ImageDataGenerator\n",
        "    X_train_reshaped = X_train.reshape(-1, 60, 60, 1)\n",
        "\n",
        "    # T·∫°o d·ªØ li·ªáu augmentation\n",
        "    aug_iter = datagen.flow(X_train_reshaped, y_train, batch_size=32)\n",
        "\n",
        "    # T·∫°o batch d·ªØ li·ªáu augmentation\n",
        "    X_augmented = []\n",
        "    y_augmented = []\n",
        "\n",
        "    for i in range(len(X_train) // 32):  # T·∫°o th√™m d·ªØ li·ªáu g·∫•p ƒë√¥i\n",
        "        X_batch, y_batch = next(aug_iter)\n",
        "        X_augmented.append(X_batch.reshape(-1, 60 * 60))\n",
        "        y_augmented.append(y_batch)\n",
        "\n",
        "    # K·∫øt h·ª£p d·ªØ li·ªáu g·ªëc v√† d·ªØ li·ªáu augmentation\n",
        "    X_combined = np.vstack([X_train] + X_augmented)\n",
        "    y_combined = np.vstack([y_train] + y_augmented)\n",
        "\n",
        "    return X_combined, y_combined\n",
        "\n",
        "\n",
        "def plot_training_history(history):\n",
        "    # V·∫Ω ƒë·ªì th·ªã accuracy v√† loss\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Main training code\n",
        "try:\n",
        "    data_dir = \"train\"\n",
        "    if not os.path.exists(data_dir):\n",
        "        raise FileNotFoundError(f\"Th∆∞ m·ª•c {data_dir} kh√¥ng t·ªìn t·∫°i!\")\n",
        "\n",
        "    # T·∫£i d·ªØ li·ªáu\n",
        "    (X_train, y_train), (X_test, y_test), class_names = load_data(data_dir)\n",
        "\n",
        "    # Chuy·ªÉn ƒë·ªïi nh√£n sang d·∫°ng categorical\n",
        "    y_train_categorical = to_categorical(y_train, num_classes=len(class_names))\n",
        "    y_test_categorical = to_categorical(y_test, num_classes=len(class_names))\n",
        "\n",
        "    print(f\"S·ªë ng∆∞·ªùi nh·∫≠n d·∫°ng: {len(class_names)}\")\n",
        "    print(f\"T√™n ng∆∞·ªùi nh·∫≠n d·∫°ng: {class_names}\")\n",
        "    print(f\"K√≠ch th∆∞·ªõc d·ªØ li·ªáu hu·∫•n luy·ªán: {X_train.shape}\")\n",
        "    print(f\"K√≠ch th∆∞·ªõc d·ªØ li·ªáu ki·ªÉm tra: {X_test.shape}\")\n",
        "\n",
        "    # T·∫°o v√† hu·∫•n luy·ªán m√¥ h√¨nh\n",
        "    model = create_model((60 * 60,), len(class_names))\n",
        "    model.summary()\n",
        "\n",
        "    # Augmentation d·ªØ li·ªáu\n",
        "    X_train_aug, y_train_aug = augment_data(X_train, y_train_categorical)\n",
        "    print(f\"K√≠ch th∆∞·ªõc d·ªØ li·ªáu sau augmentation: {X_train_aug.shape}\")\n",
        "\n",
        "    # Hu·∫•n luy·ªán m√¥ h√¨nh\n",
        "    history = model.fit(\n",
        "        X_train_aug, y_train_aug,\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        validation_data=(X_test, y_test_categorical),\n",
        "        verbose=1,\n",
        "        callbacks=[\n",
        "            # D·ª´ng s·ªõm n·∫øu validation loss kh√¥ng c·∫£i thi·ªán sau 10 epochs\n",
        "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "            # Gi·∫£m learning rate n·∫øu validation loss kh√¥ng c·∫£i thi·ªán\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    #V·∫Ω ƒë·ªì th·ªã qu√° tr√¨nh hu·∫•n luy·ªán\n",
        "    plot_training_history(history)\n",
        "\n",
        "    # ƒê√°nh gi√° m√¥ h√¨nh\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test_categorical, verbose=0)\n",
        "    print(f\"ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p test: {test_accuracy:.4f}\")\n",
        "\n",
        "    #D·ª± ƒëo√°n\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true = np.argmax(y_test_categorical, axis=1)\n",
        "\n",
        "    model.save(\"flower_detect_mnist_style.keras\")    #L∆∞u m√¥ h√¨nh\n",
        "\n",
        "    #Ki·ªÉm tra ƒë·ªô ch√≠nh x√°c tr√™n t·ª´ng l·ªõp (ƒë·ªì ƒÉn c·∫ßn nh·∫≠n di·ªán)\n",
        "    class_accuracy = {}\n",
        "    for i, cls_name in enumerate(class_names):\n",
        "        class_mask = (y_true == i)\n",
        "        if np.sum(class_mask) > 0:\n",
        "            class_acc = np.mean(y_pred_classes[class_mask] == y_true[class_mask])\n",
        "            class_accuracy[cls_name] = class_acc\n",
        "            print(f\"ƒê·ªô ch√≠nh x√°c khi hu·∫•n luy·ªán data c·ªßa {cls_name}: {class_acc:.4f}\")\n",
        "\n",
        "except Exception as e: #khi train kh√¥ng th√†nh c√¥ng th√¨ in ra l·ªói\n",
        "    print(f\"L·ªói: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcDwrihCNoSh",
        "outputId": "d0db8bf4-d916-4af2-929f-90c2bc94305f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L·ªói: Th∆∞ m·ª•c train kh√¥ng t·ªìn t·∫°i!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-294854403.py\", line 138, in <cell line: 0>\n",
            "    raise FileNotFoundError(f\"Th∆∞ m·ª•c {data_dir} kh√¥ng t·ªìn t·∫°i!\")\n",
            "FileNotFoundError: Th∆∞ m·ª•c train kh√¥ng t·ªìn t·∫°i!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Giao di·ªán ƒë·ªì ƒÉn\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "import tkinter as tk\n",
        "from tkinter import ttk, filedialog, messagebox\n",
        "from PIL import Image, ImageTk\n",
        "import os\n",
        "\n",
        "model = load_model(\"food_detect.keras\")\n",
        "class_names = [\"pizza\", \"burger\", \"sushi\", \"noodles\", \"fried_chicken\"]\n",
        "flower_info = {\n",
        "    \"pizza\": [\n",
        "        \"Pizza l√† m√≥n ƒÉn n·ªïi ti·∫øng c√≥ ngu·ªìn g·ªëc t·ª´ √ù.\",\n",
        "        \"ƒê∆∞·ª£c l√†m t·ª´ b·ªôt m√¨, ph√¥ mai, s·ªët c√† chua v√† nhi·ªÅu lo·∫°i topping kh√°c nhau.\",\n",
        "        \"Pizza ng√†y nay ph·ªï bi·∫øn to√†n c·∫ßu v·ªõi nhi·ªÅu bi·∫øn th·ªÉ, t·ª´ pizza h·∫£i s·∫£n, pizza ph√¥ mai ƒë·∫øn pizza chay.\",\n",
        "        \"ƒê√¢y l√† m√≥n ƒÉn th∆∞·ªùng g·∫Øn li·ªÅn v·ªõi s·ª± sum h·ªçp gia ƒë√¨nh, b·∫°n b√®.\"\n",
        "    ],\n",
        "    \"burger\": [\n",
        "        \"Burger (b√°nh m√¨ k·∫πp th·ªãt) c√≥ ngu·ªìn g·ªëc t·ª´ ƒê·ª©c v√† M·ªπ.\",\n",
        "        \"Nguy√™n li·ªáu ch√≠nh th∆∞·ªùng g·ªìm: b√°nh m√¨, th·ªãt b√≤ n∆∞·ªõng, rau x√† l√°ch, c√† chua, ph√¥ mai v√† s·ªët.\",\n",
        "        \"Burger l√† m√≥n ƒÉn nhanh ph·ªï bi·∫øn nh·∫•t th·∫ø gi·ªõi, ƒë·∫∑c bi·ªát trong c√°c chu·ªói fast food.\"\n",
        "        \"Ngo√†i th·ªãt b√≤, burger c√≤n c√≥ nhi·ªÅu bi·∫øn th·ªÉ v·ªõi th·ªãt g√†, c√°, ho·∫∑c chay.\"\n",
        "    ],\n",
        "    \"sushi\": [\n",
        "        \"Sushi l√† m√≥n ƒÉn truy·ªÅn th·ªëng c·ªßa Nh·∫≠t B·∫£n.\",\n",
        "        \"Nguy√™n li·ªáu ch√≠nh l√† c∆°m tr·ªôn gi·∫•m k·∫øt h·ª£p v·ªõi h·∫£i s·∫£n t∆∞∆°i s·ªëng, rau c·ªß ho·∫∑c tr·ª©ng.\",\n",
        "        \"Sushi kh√¥ng ch·ªâ l√† m√≥n ƒÉn m√† c√≤n l√† ngh·ªá thu·∫≠t tr√¨nh b√†y tinh t·∫ø c·ªßa ·∫©m th·ª±c Nh·∫≠t.\",\n",
        "        \"C√°c lo·∫°i sushi ph·ªï bi·∫øn: Nigiri, Maki, Sashimi, Temaki.\"\n",
        "    ],\n",
        "    \"noodles\": [\n",
        "        \"Noodles (m√¨) l√† m√≥n ƒÉn ph·ªï bi·∫øn kh·∫Øp ch√¢u √Å.\",\n",
        "        \"C√≥ nhi·ªÅu lo·∫°i m√¨: m√¨ t∆∞∆°i, m√¨ kh√¥, m√¨ g√≥i, v·ªõi ƒëa d·∫°ng c√°ch ch·∫ø bi·∫øn nh∆∞ x√†o, n·∫•u, tr·ªôn.\",\n",
        "        \"M√¨ th∆∞·ªùng ƒÉn k√®m v·ªõi th·ªãt, h·∫£i s·∫£n, rau c·ªß v√† nhi·ªÅu lo·∫°i gia v·ªã kh√°c nhau.\"\n",
        "        \"·ªû Vi·ªát Nam, m√¨ g√≥i l√† m√≥n ƒÉn nhanh quen thu·ªôc, ti·ªán l·ª£i v√† ph·ªï bi·∫øn.\"\n",
        "    ],\n",
        "    \"fried_chicken\": [\n",
        "        \"Fried Chicken (g√† r√°n) l√† m√≥n ƒÉn n·ªïi ti·∫øng to√†n c·∫ßu, ƒë·∫∑c bi·ªát g·∫Øn li·ªÅn v·ªõi ·∫©m th·ª±c M·ªπ.\",\n",
        "        \"Th·ªãt g√† ƒë∆∞·ª£c t·∫©m b·ªôt, chi√™n gi√≤n, v√†ng ru·ªôm v√† c√≥ h∆∞∆°ng v·ªã h·∫•p d·∫´n.\",\n",
        "        \"G√† r√°n th∆∞·ªùng ƒÉn k√®m v·ªõi khoai t√¢y chi√™n, salad v√† n∆∞·ªõc ng·ªçt.\",\n",
        "        \"C√°c th∆∞∆°ng hi·ªáu g√† r√°n n·ªïi ti·∫øng: KFC, Popeyes, Lotteria.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "class FlowerRecognitionUI:\n",
        "    def __init__(self, root):\n",
        "        self.root = root\n",
        "        self.root.title(\"·ª®ng d·ª•ng Nh·∫≠n Di·ªán M√≥n ƒÇn\")\n",
        "        self.root.geometry(\"1200x800\")\n",
        "        self.root.configure(bg=\"#f0f0f0\")\n",
        "\n",
        "        # Bi·∫øn l∆∞u tr·ªØ\n",
        "        self.image_path = None\n",
        "        self.cap = None\n",
        "        self.webcam_running = False\n",
        "        self.current_frame = None\n",
        "        self.photo = None\n",
        "        self.original_image = None\n",
        "        self.webcam_image = None\n",
        "        self.create_widgets()\n",
        "        self.start_webcam()\n",
        "\n",
        "    def create_widgets(self):\n",
        "        # Configure style\n",
        "        style = ttk.Style()\n",
        "        style.configure('TFrame', background='#f0f0f0')\n",
        "        style.configure('TLabel', background='#f0f0f0', font=('Arial', 10))\n",
        "        style.configure('Title.TLabel', background='#f0f0f0', font=('Arial', 20, 'bold'), foreground='#2c3e50')\n",
        "        style.configure('Result.TLabel', background='#f0f0f0', font=('Arial', 18, 'bold'), foreground='#27ae60')\n",
        "        style.configure('TButton', font=('Arial', 12), padding=8)\n",
        "        style.configure('TLabelFrame', font=('Arial', 12, 'bold'), background='#f0f0f0')\n",
        "\n",
        "        # Main container\n",
        "        main_frame = ttk.Frame(self.root, padding=\"20\")\n",
        "        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
        "\n",
        "        # Title\n",
        "        title_label = ttk.Label(main_frame, text=\"H·ªÜ TH·ªêNG NH·∫¨N DI·ªÜN M√ìN ƒÇN\",\n",
        "                                style='Title.TLabel')\n",
        "        title_label.grid(row=0, column=0, columnspan=2, pady=(0, 20))\n",
        "\n",
        "        # Left frame for controls and info\n",
        "        left_frame = ttk.Frame(main_frame)\n",
        "        left_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), padx=(0, 20))\n",
        "\n",
        "        # Right frame for image/webcam\n",
        "        right_frame = ttk.Frame(main_frame)\n",
        "        right_frame.grid(row=1, column=1, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
        "\n",
        "        # Selection frame\n",
        "        select_frame = ttk.Frame(left_frame)\n",
        "        select_frame.grid(row=0, column=0, pady=(0, 20), sticky=(tk.W, tk.E))\n",
        "\n",
        "        # Select button\n",
        "        self.select_btn = ttk.Button(select_frame, text=\"üìÅ CH·ªåN ·∫¢NH V√Ä NH·∫¨N DI·ªÜN\",\n",
        "                                     command=self.select_and_recognize, width=25)\n",
        "        self.select_btn.grid(row=0, column=0, padx=(0, 10))\n",
        "\n",
        "        # Webcam button\n",
        "        self.webcam_btn = ttk.Button(select_frame, text=\"üì∑ B·∫¨T/T·∫ÆT WEBCAM\",\n",
        "                                     command=self.toggle_webcam, width=20)\n",
        "        self.webcam_btn.grid(row=0, column=1)\n",
        "\n",
        "        # Path label\n",
        "        self.path_label = ttk.Label(select_frame, text=\"Ch∆∞a ch·ªçn ·∫£nh n√†o\",\n",
        "                                    foreground=\"#7f8c8d\", font=('Arial', 11))\n",
        "        self.path_label.grid(row=1, column=0, columnspan=2, pady=(10, 0), sticky=tk.W)\n",
        "\n",
        "        # Result frame\n",
        "        result_frame = ttk.LabelFrame(left_frame, text=\"K·∫æT QU·∫¢ NH·∫¨N DI·ªÜN\", padding=\"15\")\n",
        "        result_frame.grid(row=1, column=0, pady=(0, 20), sticky=(tk.W, tk.E))\n",
        "\n",
        "        # Result display - centered and larger\n",
        "        self.result_var = tk.StringVar(value=\"üîÑ Ch∆∞a c√≥ k·∫øt qu·∫£\")\n",
        "        result_display = tk.Label(result_frame, textvariable=self.result_var,\n",
        "                                  font=('Arial', 18, 'bold'), foreground=\"#2c3e50\",\n",
        "                                  background='#ecf0f1', justify=tk.CENTER,\n",
        "                                  wraplength=400, padx=20, pady=20,\n",
        "                                  relief=tk.RIDGE, borderwidth=2)\n",
        "        result_display.grid(row=0, column=0, pady=10)\n",
        "\n",
        "        # Information frame\n",
        "        info_frame = ttk.LabelFrame(left_frame, text=\"TH√îNG TIN CHI TI·∫æT\", padding=\"15\")\n",
        "        info_frame.grid(row=2, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
        "\n",
        "        # Text box for information\n",
        "        self.info_text = tk.Text(info_frame, width=60, height=15, font=('Arial', 11),\n",
        "                                 wrap=tk.WORD, state=tk.DISABLED, bg='#ffffff',\n",
        "                                 relief=tk.FLAT, borderwidth=1, padx=15, pady=15)\n",
        "        self.info_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
        "\n",
        "        # Scrollbars for text box\n",
        "        v_scrollbar = ttk.Scrollbar(info_frame, orient=tk.VERTICAL, command=self.info_text.yview)\n",
        "        v_scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))\n",
        "\n",
        "        h_scrollbar = ttk.Scrollbar(info_frame, orient=tk.HORIZONTAL, command=self.info_text.xview)\n",
        "        h_scrollbar.grid(row=1, column=0, sticky=(tk.W, tk.E))\n",
        "\n",
        "        self.info_text.configure(yscrollcommand=v_scrollbar.set, xscrollcommand=h_scrollbar.set)\n",
        "\n",
        "        # Image/Webcam display frame\n",
        "        display_frame = ttk.LabelFrame(right_frame, text=\"XEM TR∆Ø·ªöC ·∫¢NH/WEBCAM\", padding=\"10\")\n",
        "        display_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
        "\n",
        "        # Image label for displaying selected image or webcam - FIXED SIZE\n",
        "        self.image_label = tk.Label(display_frame, bg=\"#2c3e50\", width=50, height=30,\n",
        "                                    relief=tk.SUNKEN, text=\"Webcam ƒëang kh·ªüi ƒë·ªông...\")\n",
        "        self.image_label.grid(row=0, column=0, pady=10, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
        "\n",
        "        # Configure grid to expand the label\n",
        "        display_frame.columnconfigure(0, weight=1)\n",
        "        display_frame.rowconfigure(0, weight=1)\n",
        "\n",
        "        # Capture button\n",
        "        self.capture_btn = ttk.Button(display_frame, text=\"üì∏ CH·ª§P ·∫¢NH V√Ä NH·∫¨N DI·ªÜN\",\n",
        "                                      command=self.capture_and_recognize, width=30)\n",
        "        self.capture_btn.grid(row=1, column=0, pady=10)\n",
        "\n",
        "        # Configure grid weights for resizing\n",
        "        self.root.columnconfigure(0, weight=1)\n",
        "        self.root.rowconfigure(0, weight=1)\n",
        "\n",
        "        main_frame.columnconfigure(0, weight=1)\n",
        "        main_frame.columnconfigure(1, weight=1)\n",
        "        main_frame.rowconfigure(1, weight=1)\n",
        "\n",
        "        left_frame.columnconfigure(0, weight=1)\n",
        "        left_frame.rowconfigure(2, weight=1)\n",
        "\n",
        "        right_frame.columnconfigure(0, weight=1)\n",
        "        right_frame.rowconfigure(0, weight=1)\n",
        "\n",
        "        info_frame.columnconfigure(0, weight=1)\n",
        "        info_frame.rowconfigure(0, weight=1)\n",
        "\n",
        "    def start_webcam(self):\n",
        "        \"\"\"Kh·ªüi ƒë·ªông webcam\"\"\"\n",
        "        try:\n",
        "            self.cap = cv2.VideoCapture(0)\n",
        "            if not self.cap.isOpened():\n",
        "                messagebox.showerror(\"L·ªói\", \"Kh√¥ng th·ªÉ truy c·∫≠p webcam!\")\n",
        "                return\n",
        "\n",
        "            self.webcam_running = True\n",
        "            self.update_webcam()\n",
        "\n",
        "        except Exception as e:\n",
        "            messagebox.showerror(\"L·ªói\", f\"Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông webcam: {str(e)}\")\n",
        "\n",
        "    def stop_webcam(self):\n",
        "        self.webcam_running = False\n",
        "        if self.cap:\n",
        "            self.cap.release()\n",
        "        self.cap = None\n",
        "\n",
        "    def toggle_webcam(self):\n",
        "        if self.webcam_running:\n",
        "            self.stop_webcam()\n",
        "            self.webcam_btn.configure(text=\"üì∑ B·∫¨T WEBCAM\")\n",
        "            self.image_label.configure(image='', text=\"Webcam ƒë√£ t·∫Øt\", bg=\"#2c3e50\", fg=\"white\")\n",
        "        else:\n",
        "            self.start_webcam()\n",
        "            self.webcam_btn.configure(text=\"üì∑ T·∫ÆT WEBCAM\")\n",
        "\n",
        "    def update_webcam(self):\n",
        "        if self.webcam_running and self.cap and self.cap.isOpened():\n",
        "            ret, frame = self.cap.read()\n",
        "            if ret:\n",
        "                self.webcam_image = frame.copy()\n",
        "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                h, w = frame.shape[:2]\n",
        "                label_width = self.image_label.winfo_width()\n",
        "                label_height = self.image_label.winfo_height()\n",
        "                if label_width <= 1:\n",
        "                    label_width = 400\n",
        "                    label_height = 300\n",
        "\n",
        "                ratio = min(label_width / w, label_height / h)\n",
        "                new_w, new_h = int(w * ratio), int(h * ratio)\n",
        "                if new_w < 100:\n",
        "                    new_w = 100\n",
        "                if new_h < 100:\n",
        "                    new_h = 100\n",
        "\n",
        "                frame_resized = cv2.resize(frame_rgb, (new_w, new_h))\n",
        "                self.photo = ImageTk.PhotoImage(image=Image.fromarray(frame_resized))\n",
        "                self.image_label.configure(image=self.photo, text=\"\")\n",
        "            if self.webcam_running:\n",
        "                self.root.after(10, self.update_webcam)\n",
        "        else:\n",
        "            self.image_label.configure(image='', text=\"Kh√¥ng c√≥ t√≠n hi·ªáu webcam\", bg=\"#2c3e50\", fg=\"white\")\n",
        "\n",
        "    def display_image(self, image):\n",
        "        if image is None:\n",
        "            return\n",
        "        if len(image.shape) == 3:\n",
        "            img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        else:\n",
        "            img_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "        img_pil = Image.fromarray(img_rgb)\n",
        "        label_width = self.image_label.winfo_width()\n",
        "        label_height = self.image_label.winfo_height()\n",
        "        if label_width <= 1:\n",
        "            label_width = 400\n",
        "            label_height = 300\n",
        "\n",
        "        w, h = img_pil.size\n",
        "        ratio = min(label_width / w, label_height / h)\n",
        "        new_w, new_h = int(w * ratio), int(h * ratio)\n",
        "\n",
        "        if new_w < 100:\n",
        "            new_w = 100\n",
        "        if new_h < 100:\n",
        "            new_h = 100\n",
        "\n",
        "        img_resized = img_pil.resize((new_w, new_h), Image.Resampling.LANCZOS)\n",
        "        photo = ImageTk.PhotoImage(img_resized)\n",
        "        self.image_label.config(image=photo)\n",
        "        self.image_label.image = photo\n",
        "\n",
        "    def capture_and_recognize(self):\n",
        "        if self.webcam_image is not None:\n",
        "            self.original_image = self.webcam_image.copy()\n",
        "            self.display_image(self.original_image)\n",
        "            self.path_label.configure(text=f\"ƒê√£ ch·ª•p ·∫£nh t·ª´ webcam\")\n",
        "            self.recognize_flower(self.webcam_image, source=\"webcam\")\n",
        "        else:\n",
        "            messagebox.showwarning(\"C·∫£nh b√°o\", \"Kh√¥ng c√≥ frame n√†o t·ª´ webcam!\")\n",
        "\n",
        "    def select_and_recognize(self):\n",
        "        file_path = filedialog.askopenfilename(\n",
        "            title=\"Ch·ªçn ·∫£nh lo√†i hoa\",\n",
        "            filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png *.bmp\")]\n",
        "        )\n",
        "        if file_path:\n",
        "            self.image_path = file_path\n",
        "            self.original_image = cv2.imread(file_path)\n",
        "            if self.original_image is None:\n",
        "                self.original_image = cv2.imdecode(np.fromfile(file_path, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
        "            if self.original_image is None:\n",
        "                messagebox.showerror(\"L·ªói\", \"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh!\")\n",
        "                return\n",
        "            self.display_image(self.original_image)\n",
        "            try:\n",
        "                self.path_label.configure(text=f\"ƒê√£ ch·ªçn: {os.path.basename(file_path)}\")\n",
        "                self.recognize_flower(self.original_image, source=\"file\")\n",
        "            except Exception as e:\n",
        "                messagebox.showerror(\"L·ªói\", f\"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {str(e)}\")\n",
        "\n",
        "    def recognize_flower(self, image, source=\"file\"):\n",
        "        if image is None:\n",
        "            messagebox.showwarning(\"C·∫£nh b√°o\", \"Kh√¥ng c√≥ ·∫£nh ƒë·ªÉ nh·∫≠n di·ªán!\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            img_processed = image.copy()\n",
        "            if len(img_processed.shape) == 3:\n",
        "                img_processed = cv2.cvtColor(img_processed, cv2.COLOR_BGR2GRAY)\n",
        "            img_processed = cv2.resize(img_processed, (60, 60))\n",
        "            img_processed = cv2.equalizeHist(img_processed)\n",
        "            img_processed = cv2.GaussianBlur(img_processed, (3, 3), 0)\n",
        "            img_processed = img_processed.astype(\"float32\") / 255.0\n",
        "            img_processed = img_processed.reshape(1, 60 * 60)\n",
        "\n",
        "            predictions = model.predict(img_processed, verbose=0)\n",
        "            class_idx = np.argmax(predictions)\n",
        "            predicted_name = class_names[class_idx]\n",
        "            confidence = predictions[0][class_idx] * 100\n",
        "\n",
        "            self.result_var.set(\n",
        "                f\"‚úÖ NH·∫¨N DI·ªÜN TH√ÄNH C√îNG!\\n\\nK·∫øt qu·∫£: {predicted_name}\\nƒê·ªô ch√≠nh x√°c: {confidence:.2f}%\")\n",
        "\n",
        "            self.show_flower_info(predicted_name)\n",
        "\n",
        "        except Exception as e:\n",
        "            messagebox.showerror(\"Th√¥ng b√°o\", f\"Up ·∫£nh th√†nh c√¥ng\")\n",
        "\n",
        "    def show_flower_info(self, flower_name):\n",
        "        info = flower_info.get(flower_name, [])\n",
        "\n",
        "        self.info_text.configure(state=tk.NORMAL)\n",
        "        self.info_text.delete(1.0, tk.END)\n",
        "\n",
        "        # Display flower information with formatting\n",
        "        self.info_text.insert(tk.END, f\"TH√îNG TIN CHI TI·∫æT - {flower_name.upper()}\\n\\n\", \"title\")\n",
        "        self.info_text.tag_configure(\"title\", font=('Arial', 14, 'bold'), foreground='#2980b9')\n",
        "\n",
        "        for line in info:\n",
        "            self.info_text.insert(tk.END, f\"‚Ä¢ {line}\\n\\n\")\n",
        "\n",
        "        self.info_text.configure(state=tk.DISABLED)\n",
        "\n",
        "    def __del__(self):\n",
        "        if self.cap:\n",
        "            self.cap.release()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    root = tk.Tk()\n",
        "    app = FlowerRecognitionUI(root)\n",
        "    root.protocol(\"WM_DELETE_WINDOW\", lambda: (app.stop_webcam(), root.destroy()))\n",
        "    root.mainloop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "4u0PQVeSIQR5",
        "outputId": "2f9f62ee-63aa-48aa-8731-017b8b716239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "File not found: filepath=food_detect.keras. Please ensure the file is an accessible `.keras` zip file.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3697632524.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"food_detect.keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"pizza\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"burger\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sushi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"noodles\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fried_chicken\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m flower_info = {\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n\u001b[1;32m    199\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0;34mf\"File not found: filepath={filepath}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;34m\"Please ensure the file is an accessible `.keras` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File not found: filepath=food_detect.keras. Please ensure the file is an accessible `.keras` zip file."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ch·ªâ tay\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#x·ª≠ l√Ω th∆∞ m·ª•c, file c·ªßa data\n",
        "def load_data(data_dir, img_size=(60, 60), test_size=0.2):\n",
        "    X, y = [], []\n",
        "    class_names = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
        "    class_map = {cls_name: idx for idx, cls_name in enumerate(class_names)}\n",
        "\n",
        "    for cls in class_names:\n",
        "        cls_path = os.path.join(data_dir, cls)\n",
        "        for file in os.listdir(cls_path):\n",
        "            if file.lower().endswith((\".jpg\", \".png\", \".jpeg\", \".bmp\", \".HEIC\")):\n",
        "                img_path = os.path.join(cls_path, file)\n",
        "                try:\n",
        "                    img = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error decoding image {img_path}: {e}\")\n",
        "                    continue\n",
        "\n",
        "                    # Ti·ªÅn x·ª≠ l√Ω ·∫£nh\n",
        "                img = cv2.resize(img, img_size)\n",
        "                img = cv2.equalizeHist(img)  # C√¢n b·∫±ng histogram ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô t∆∞∆°ng ph·∫£n\n",
        "                img = cv2.GaussianBlur(img, (3, 3), 0)  # L√†m m·ªù ƒë·ªÉ gi·∫£m nhi·ªÖu\n",
        "                img = img.astype(\"float32\") / 255.0\n",
        "                X.append(img)\n",
        "                y.append(class_map[cls])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    X = X.reshape((X.shape[0], img_size[0] * img_size[1]))\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
        "    return (X_train, y_train), (X_test, y_test), class_names\n",
        "\n",
        "\n",
        "def create_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    # M·∫°ng neural s√¢u h∆°n v·ªõi c√°c k·ªπ thu·∫≠t ch·ªëng overfitting\n",
        "    model.add(Dense(1024, activation='relu', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # S·ª≠ d·ª•ng optimizer t·ªët h∆°n\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def augment_data(X_train, y_train):\n",
        "    # T·∫°o d·ªØ li·ªáu augmentation\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=20,  # Xoay ·∫£nh ng·∫´u nhi√™n ¬±20 ƒë·ªô\n",
        "        width_shift_range=0.2,  # D·ªãch chuy·ªÉn ngang ng·∫´u nhi√™n 20%\n",
        "        height_shift_range=0.2,  # D·ªãch chuy·ªÉn d·ªçc ng·∫´u nhi√™n 20%\n",
        "        shear_range=0.2,  # Bi·∫øn d·∫°ng c·∫Øt ng·∫´u nhi√™n 20%\n",
        "        zoom_range=0.2,  # Zoom ng·∫´u nhi√™n ¬±20%\n",
        "        horizontal_flip=True,  # L·∫≠t ngang ng·∫´u nhi√™n\n",
        "        fill_mode='nearest'  # ƒêi·ªÅn pixel g·∫ßn nh·∫•t khi bi·∫øn ƒë·ªïi\n",
        "    )\n",
        "\n",
        "    # Reshape d·ªØ li·ªáu ƒë·ªÉ ph√π h·ª£p v·ªõi ImageDataGenerator\n",
        "    X_train_reshaped = X_train.reshape(-1, 60, 60, 1)\n",
        "\n",
        "    # T·∫°o d·ªØ li·ªáu augmentation\n",
        "    aug_iter = datagen.flow(X_train_reshaped, y_train, batch_size=32)\n",
        "\n",
        "    # T·∫°o batch d·ªØ li·ªáu augmentation\n",
        "    X_augmented = []\n",
        "    y_augmented = []\n",
        "\n",
        "    for i in range(len(X_train) // 32):  # T·∫°o th√™m d·ªØ li·ªáu g·∫•p ƒë√¥i\n",
        "        X_batch, y_batch = next(aug_iter)\n",
        "        X_augmented.append(X_batch.reshape(-1, 60 * 60))\n",
        "        y_augmented.append(y_batch)\n",
        "\n",
        "    # K·∫øt h·ª£p d·ªØ li·ªáu g·ªëc v√† d·ªØ li·ªáu augmentation\n",
        "    X_combined = np.vstack([X_train] + X_augmented)\n",
        "    y_combined = np.vstack([y_train] + y_augmented)\n",
        "\n",
        "    return X_combined, y_combined\n",
        "\n",
        "\n",
        "def plot_training_history(history):\n",
        "    # V·∫Ω ƒë·ªì th·ªã accuracy v√† loss\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Main training code\n",
        "try:\n",
        "    data_dir = \"train\"\n",
        "    if not os.path.exists(data_dir):\n",
        "        raise FileNotFoundError(f\"Th∆∞ m·ª•c {data_dir} kh√¥ng t·ªìn t·∫°i!\")\n",
        "\n",
        "    # T·∫£i d·ªØ li·ªáu\n",
        "    (X_train, y_train), (X_test, y_test), class_names = load_data(data_dir)\n",
        "\n",
        "    # Chuy·ªÉn ƒë·ªïi nh√£n sang d·∫°ng categorical\n",
        "    y_train_categorical = to_categorical(y_train, num_classes=len(class_names))\n",
        "    y_test_categorical = to_categorical(y_test, num_classes=len(class_names))\n",
        "\n",
        "    print(f\"S·ªë ng∆∞·ªùi nh·∫≠n d·∫°ng: {len(class_names)}\")\n",
        "    print(f\"T√™n ng∆∞·ªùi nh·∫≠n d·∫°ng: {class_names}\")\n",
        "    print(f\"K√≠ch th∆∞·ªõc d·ªØ li·ªáu hu·∫•n luy·ªán: {X_train.shape}\")\n",
        "    print(f\"K√≠ch th∆∞·ªõc d·ªØ li·ªáu ki·ªÉm tra: {X_test.shape}\")\n",
        "\n",
        "    # T·∫°o v√† hu·∫•n luy·ªán m√¥ h√¨nh\n",
        "    model = create_model((60 * 60,), len(class_names))\n",
        "    model.summary()\n",
        "\n",
        "    # Augmentation d·ªØ li·ªáu\n",
        "    X_train_aug, y_train_aug = augment_data(X_train, y_train_categorical)\n",
        "    print(f\"K√≠ch th∆∞·ªõc d·ªØ li·ªáu sau augmentation: {X_train_aug.shape}\")\n",
        "\n",
        "    # Hu·∫•n luy·ªán m√¥ h√¨nh\n",
        "    history = model.fit(\n",
        "        X_train_aug, y_train_aug,\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        validation_data=(X_test, y_test_categorical),\n",
        "        verbose=1,\n",
        "        callbacks=[\n",
        "            # D·ª´ng s·ªõm n·∫øu validation loss kh√¥ng c·∫£i thi·ªán sau 10 epochs\n",
        "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "            # Gi·∫£m learning rate n·∫øu validation loss kh√¥ng c·∫£i thi·ªán\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    #V·∫Ω ƒë·ªì th·ªã qu√° tr√¨nh hu·∫•n luy·ªán\n",
        "    plot_training_history(history)\n",
        "\n",
        "    # ƒê√°nh gi√° m√¥ h√¨nh\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test_categorical, verbose=0)\n",
        "    print(f\"ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p test: {test_accuracy:.4f}\")\n",
        "\n",
        "    #D·ª± ƒëo√°n\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true = np.argmax(y_test_categorical, axis=1)\n",
        "\n",
        "    model.save(\"flower_detect_mnist_style.keras\")    #L∆∞u m√¥ h√¨nh\n",
        "\n",
        "    #Ki·ªÉm tra ƒë·ªô ch√≠nh x√°c tr√™n t·ª´ng l·ªõp (ch·ªâ tay c·∫ßn nh·∫≠n di·ªán)\n",
        "    class_accuracy = {}\n",
        "    for i, cls_name in enumerate(class_names):\n",
        "        class_mask = (y_true == i)\n",
        "        if np.sum(class_mask) > 0:\n",
        "            class_acc = np.mean(y_pred_classes[class_mask] == y_true[class_mask])\n",
        "            class_accuracy[cls_name] = class_acc\n",
        "            print(f\"ƒê·ªô ch√≠nh x√°c khi hu·∫•n luy·ªán data c·ªßa {cls_name}: {class_acc:.4f}\")\n",
        "\n",
        "except Exception as e: #khi train kh√¥ng th√†nh c√¥ng th√¨ in ra l·ªói\n",
        "    print(f\"L·ªói: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "id": "lKx-9_HRhwwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# giao di·ªán ch·ªâ tay\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "import tkinter as tk\n",
        "from tkinter import ttk, filedialog, messagebox\n",
        "from PIL import Image, ImageTk\n",
        "import os\n",
        "\n",
        "# Load model (b·∫°n c·∫ßn hu·∫•n luy·ªán tr∆∞·ªõc v·ªõi d·ªØ li·ªáu ch·ªâ tay)\n",
        "model = load_model(\"palm_detect_model.keras\")\n",
        "\n",
        "# C√°c lo·∫°i ch·ªâ tay\n",
        "class_names = [\"Ch·ªâ tay Ng∆∞·ªùi Gi√†u\", \"Ch·ªâ tay Ng∆∞·ªùi Ngh√®o\", \"Ch·ªâ tay Ng∆∞·ªùi B√¨nh Th∆∞·ªùng\"]\n",
        "\n",
        "# Th√¥ng tin chi ti·∫øt\n",
        "palm_info = {\n",
        "    \"Ch·ªâ tay Ng∆∞·ªùi Gi√†u\": [\n",
        "        \"ƒê·∫∑c ƒëi·ªÉm: ƒë∆∞·ªùng t√†i l·ªôc r√µ r√†ng, ƒë·∫≠m n√©t, k√©o d√†i ƒë·∫øn g√≤ M·ªôc tinh.\",\n",
        "        \"Th∆∞·ªùng c√≥ th√™m c√°c ƒë∆∞·ªùng may m·∫Øn song song ho·∫∑c c·∫Øt ch√©o ƒë·∫πp.\",\n",
        "        \"√ù nghƒ©a: ng∆∞·ªùi c√≥ s·ª± nghi·ªáp thƒÉng ti·∫øn, t√†i ch√≠nh ·ªïn ƒë·ªãnh, nhi·ªÅu c∆° h·ªôi l√†m gi√†u.\"\n",
        "    ],\n",
        "    \"Ch·ªâ tay Ng∆∞·ªùi Ngh√®o\": [\n",
        "        \"ƒê·∫∑c ƒëi·ªÉm: ƒë∆∞·ªùng t√†i l·ªôc m·ªù, ƒë·ª©t ƒëo·∫°n, kh√≥ nh√¨n th·∫•y.\",\n",
        "        \"ƒê∆∞·ªùng sinh ƒë·∫°o v√† tr√≠ ƒë·∫°o th∆∞·ªùng giao nhau h·ªón lo·∫°n, thi·∫øu m·∫°ch l·∫°c.\",\n",
        "        \"√ù nghƒ©a: cu·ªôc s·ªëng v·∫•t v·∫£, t√†i ch√≠nh kh√≥ khƒÉn, √≠t c∆° h·ªôi t√≠ch l≈©y.\"\n",
        "    ],\n",
        "    \"Ch·ªâ tay Ng∆∞·ªùi B√¨nh Th∆∞·ªùng\": [\n",
        "        \"ƒê·∫∑c ƒëi·ªÉm: ƒë∆∞·ªùng t√†i l·ªôc c√≥ nh∆∞ng kh√¥ng ƒë·∫≠m, kh√¥ng qu√° d√†i.\",\n",
        "        \"ƒê∆∞·ªùng sinh ƒë·∫°o v√† tr√≠ ƒë·∫°o r√µ nh∆∞ng kh√¥ng n·ªïi b·∫≠t.\",\n",
        "        \"√ù nghƒ©a: cu·ªôc s·ªëng ·ªïn ƒë·ªãnh ·ªü m·ª©c trung b√¨nh, ƒë·ªß ƒÉn ƒë·ªß m·∫∑c, √≠t bi·∫øn ƒë·ªông l·ªõn.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "class PalmRecognitionUI:\n",
        "    def __init__(self, root):\n",
        "        self.root = root\n",
        "        self.root.title(\"·ª®ng d·ª•ng Nh·∫≠n Di·ªán Ch·ªâ Tay\")\n",
        "        self.root.geometry(\"1200x800\")\n",
        "        self.root.configure(bg=\"#f0f0f0\")\n",
        "\n",
        "        # Bi·∫øn l∆∞u tr·ªØ\n",
        "        self.image_path = None\n",
        "        self.cap = None\n",
        "        self.webcam_running = False\n",
        "        self.current_frame = None\n",
        "        self.photo = None\n",
        "        self.original_image = None\n",
        "        self.webcam_image = None\n",
        "        self.create_widgets()\n",
        "        self.start_webcam()\n",
        "\n",
        "    def create_widgets(self):\n",
        "        # Configure style\n",
        "        style = ttk.Style()\n",
        "        style.configure('TFrame', background='#f0f0f0')\n",
        "        style.configure('TLabel', background='#f0f0f0', font=('Arial', 10))\n",
        "        style.configure('Title.TLabel', background='#f0f0f0', font=('Arial', 20, 'bold'), foreground='#2c3e50')\n",
        "        style.configure('TButton', font=('Arial', 12), padding=8)\n",
        "\n",
        "        # Main container\n",
        "        main_frame = ttk.Frame(self.root, padding=\"20\")\n",
        "        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
        "\n",
        "        # Title\n",
        "        title_label = ttk.Label(main_frame, text=\"H·ªÜ TH·ªêNG NH·∫¨N DI·ªÜN CH·ªà TAY\", style='Title.TLabel')\n",
        "        title_label.grid(row=0, column=0, columnspan=2, pady=(0, 20))\n",
        "\n",
        "        # Left frame for controls and info\n",
        "        left_frame = ttk.Frame(main_frame)\n",
        "        left_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), padx=(0, 20))\n",
        "\n",
        "        # Right frame for image/webcam\n",
        "        right_frame = ttk.Frame(main_frame)\n",
        "        right_frame.grid(row=1, column=1, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
        "\n",
        "        # Selection frame\n",
        "select_frame = ttk.Frame(left_frame)\n",
        "        select_frame.grid(row=0, column=0, pady=(0, 20), sticky=(tk.W, tk.E))\n",
        "\n",
        "        # Select button\n",
        "        self.select_btn = ttk.Button(select_frame, text=\"üìÅ CH·ªåN ·∫¢NH V√Ä NH·∫¨N DI·ªÜN\",\n",
        "                                     command=self.select_and_recognize, width=25)\n",
        "        self.select_btn.grid(row=0, column=0, padx=(0, 10))\n",
        "\n",
        "        # Webcam button\n",
        "        self.webcam_btn = ttk.Button(select_frame, text=\"üì∑ B·∫¨T/T·∫ÆT WEBCAM\",\n",
        "                                     command=self.toggle_webcam, width=20)\n",
        "        self.webcam_btn.grid(row=0, column=1)\n",
        "\n",
        "        # Path label\n",
        "        self.path_label = ttk.Label(select_frame, text=\"Ch∆∞a ch·ªçn ·∫£nh n√†o\",\n",
        "                                    foreground=\"#7f8c8d\", font=('Arial', 11))\n",
        "        self.path_label.grid(row=1, column=0, columnspan=2, pady=(10, 0), sticky=tk.W)\n",
        "\n",
        "        # Result frame\n",
        "        result_frame = ttk.LabelFrame(left_frame, text=\"K·∫æT QU·∫¢ NH·∫¨N DI·ªÜN\", padding=\"15\")\n",
        "        result_frame.grid(row=1, column=0, pady=(0, 20), sticky=(tk.W, tk.E))\n",
        "\n",
        "        self.result_var = tk.StringVar(value=\"üîÑ Ch∆∞a c√≥ k·∫øt qu·∫£\")\n",
        "        result_display = tk.Label(result_frame, textvariable=self.result_var,\n",
        "                                  font=('Arial', 18, 'bold'), foreground=\"#2c3e50\",\n",
        "                                  background='#ecf0f1', justify=tk.CENTER,\n",
        "                                  wraplength=400, padx=20, pady=20,\n",
        "                                  relief=tk.RIDGE, borderwidth=2)\n",
        "        result_display.grid(row=0, column=0, pady=10)\n",
        "\n",
        "        # Information frame\n",
        "        info_frame = ttk.LabelFrame(left_frame, text=\"TH√îNG TIN CHI TI·∫æT\", padding=\"15\")\n",
        "        info_frame.grid(row=2, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
        "\n",
        "        self.info_text = tk.Text(info_frame, width=60, height=15, font=('Arial', 11),\n",
        "                                 wrap=tk.WORD, state=tk.DISABLED, bg='#ffffff',\n",
        "                                 relief=tk.FLAT, borderwidth=1, padx=15, pady=15)\n",
        "        self.info_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
        "\n",
        "        v_scrollbar = ttk.Scrollbar(info_frame, orient=tk.VERTICAL, command=self.info_text.yview)\n",
        "        v_scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))\n",
        "        self.info_text.configure(yscrollcommand=v_scrollbar.set)\n",
        "\n",
        "        # Image/Webcam display frame\n",
        "        display_frame = ttk.LabelFrame(right_frame, text=\"XEM TR∆Ø·ªöC ·∫¢NH/WEBCAM\", padding=\"10\")\n",
        "        display_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
        "\n",
        "        self.image_label = tk.Label(display_frame, bg=\"#2c3e50\", width=50, height=30,\n",
        "                                    relief=tk.SUNKEN, text=\"Webcam ƒëang kh·ªüi ƒë·ªông...\")\n",
        "        self.image_label.grid(row=0, column=0, pady=10, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
        "\n",
        "        self.capture_btn = ttk.Button(display_frame, text=\"üì∏ CH·ª§P ·∫¢NH V√Ä NH·∫¨N DI·ªÜN\",\n",
        "                                      command=self.capture_and_recognize, width=30)\n",
        "self.capture_btn.grid(row=1, column=0, pady=10)\n",
        "\n",
        "    def start_webcam(self):\n",
        "        try:\n",
        "            self.cap = cv2.VideoCapture(0)\n",
        "            if not self.cap.isOpened():\n",
        "                messagebox.showerror(\"L·ªói\", \"Kh√¥ng th·ªÉ truy c·∫≠p webcam!\")\n",
        "                return\n",
        "            self.webcam_running = True\n",
        "            self.update_webcam()\n",
        "        except Exception as e:\n",
        "            messagebox.showerror(\"L·ªói\", f\"Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông webcam: {str(e)}\")\n",
        "\n",
        "    def stop_webcam(self):\n",
        "        self.webcam_running = False\n",
        "        if self.cap:\n",
        "            self.cap.release()\n",
        "        self.cap = None\n",
        "\n",
        "    def toggle_webcam(self):\n",
        "        if self.webcam_running:\n",
        "            self.stop_webcam()\n",
        "            self.webcam_btn.configure(text=\"üì∑ B·∫¨T WEBCAM\")\n",
        "            self.image_label.configure(image='', text=\"Webcam ƒë√£ t·∫Øt\", bg=\"#2c3e50\", fg=\"white\")\n",
        "        else:\n",
        "            self.start_webcam()\n",
        "            self.webcam_btn.configure(text=\"üì∑ T·∫ÆT WEBCAM\")\n",
        "\n",
        "    def update_webcam(self):\n",
        "        if self.webcam_running and self.cap and self.cap.isOpened():\n",
        "            ret, frame = self.cap.read()\n",
        "            if ret:\n",
        "                self.webcam_image = frame.copy()\n",
        "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                frame_resized = cv2.resize(frame_rgb, (400, 300))\n",
        "                self.photo = ImageTk.PhotoImage(image=Image.fromarray(frame_resized))\n",
        "                self.image_label.configure(image=self.photo, text=\"\")\n",
        "            if self.webcam_running:\n",
        "                self.root.after(10, self.update_webcam)\n",
        "\n",
        "    def display_image(self, image):\n",
        "        if image is None:\n",
        "            return\n",
        "        img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        img_pil = Image.fromarray(img_rgb)\n",
        "        img_resized = img_pil.resize((400, 300), Image.Resampling.LANCZOS)\n",
        "        photo = ImageTk.PhotoImage(img_resized)\n",
        "        self.image_label.config(image=photo)\n",
        "        self.image_label.image = photo\n",
        "\n",
        "    def capture_and_recognize(self):\n",
        "        if self.webcam_image is not None:\n",
        "            self.original_image = self.webcam_image.copy()\n",
        "            self.display_image(self.original_image)\n",
        "            self.path_label.configure(text=f\"ƒê√£ ch·ª•p ·∫£nh t·ª´ webcam\")\n",
        "            self.recognize_palm(self.webcam_image, source=\"webcam\")\n",
        "        else:\n",
        "            messagebox.showwarning(\"C·∫£nh b√°o\", \"Kh√¥ng c√≥ frame n√†o t·ª´ webcam!\")\n",
        "\n",
        "    def select_and_recognize(self):\n",
        "        file_path = filedialog.askopenfilename(\n",
        "            title=\"Ch·ªçn ·∫£nh b√†n tay\",\n",
        "            filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png *.bmp\")]\n",
        "        )\n",
        "        if file_path:\n",
        "            self.image_path = file_path\n",
        "            self.original_image = cv2.imread(file_path)\n",
        "            if self.original_image is None:\n",
        "                messagebox.showerror(\"L·ªói\", \"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh!\")\n",
        "                return\n",
        "            self.display_image(self.original_image)\n",
        "self.path_label.configure(text=f\"ƒê√£ ch·ªçn: {os.path.basename(file_path)}\")\n",
        "            self.recognize_palm(self.original_image, source=\"file\")\n",
        "\n",
        "    def recognize_palm(self, image, source=\"file\"):\n",
        "        if image is None:\n",
        "            messagebox.showwarning(\"C·∫£nh b√°o\", \"Kh√¥ng c√≥ ·∫£nh ƒë·ªÉ nh·∫≠n di·ªán!\")\n",
        "            return\n",
        "        try:\n",
        "            img_processed = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            img_processed = cv2.resize(img_processed, (60, 60))\n",
        "            img_processed = img_processed.astype(\"float32\") / 255.0\n",
        "            img_processed = img_processed.reshape(1, 60 * 60)\n",
        "\n",
        "            predictions = model.predict(img_processed, verbose=0)\n",
        "            class_idx = np.argmax(predictions)\n",
        "            predicted_name = class_names[class_idx]\n",
        "            confidence = predictions[0][class_idx] * 100\n",
        "\n",
        "            self.result_var.set(\n",
        "                f\"‚úÖ NH·∫¨N DI·ªÜN TH√ÄNH C√îNG!\\n\\nK·∫øt qu·∫£: {predicted_name}\\nƒê·ªô ch√≠nh x√°c: {confidence:.2f}%\")\n",
        "\n",
        "            self.show_palm_info(predicted_name)\n",
        "\n",
        "        except Exception as e:\n",
        "            messagebox.showerror(\"L·ªói\", f\"L·ªói khi nh·∫≠n di·ªán: {str(e)}\")\n",
        "\n",
        "    def show_palm_info(self, palm_name):\n",
        "        info = palm_info.get(palm_name, [])\n",
        "        self.info_text.configure(state=tk.NORMAL)\n",
        "        self.info_text.delete(1.0, tk.END)\n",
        "        self.info_text.insert(tk.END, f\"TH√îNG TIN CHI TI·∫æT - {palm_name.upper()}\\n\\n\", \"title\")\n",
        "        self.info_text.tag_configure(\"title\", font=('Arial', 14, 'bold'), foreground='#2980b9')\n",
        "        for line in info:\n",
        "            self.info_text.insert(tk.END, f\"‚Ä¢ {line}\\n\\n\")\n",
        "        self.info_text.configure(state=tk.DISABLED)\n",
        "\n",
        "    def __del__(self):\n",
        "        if self.cap:\n",
        "            self.cap.release()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    root = tk.Tk()\n",
        "    app = PalmRecognitionUI(root)\n",
        "    root.protocol(\"WM_DELETE_WINDOW\", lambda: (app.stop_webcam(), root.destroy()))\n",
        "    root.mainloop()\n"
      ],
      "metadata": {
        "id": "Q0PhX10gh5ye"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}